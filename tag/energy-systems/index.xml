<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Energy Systems | Wenqi Cui</title>
    <link>https://wenqi-cui.github.io/tag/energy-systems/</link>
      <atom:link href="https://wenqi-cui.github.io/tag/energy-systems/index.xml" rel="self" type="application/rss+xml" />
    <description>Energy Systems</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Dec 2022 08:00:48 +0000</lastBuildDate>
    <image>
      <url>https://wenqi-cui.github.io/media/icon_hud58c95a75c7ebfda2aff7ad5a2db624a_15115_512x512_fill_lanczos_center_3.png</url>
      <title>Energy Systems</title>
      <link>https://wenqi-cui.github.io/tag/energy-systems/</link>
    </image>
    
    <item>
      <title>Efficient Reinforcement Learning Through Trajectory Generation</title>
      <link>https://wenqi-cui.github.io/project/trajgen-linear/</link>
      <pubDate>Thu, 01 Dec 2022 08:00:48 +0000</pubDate>
      <guid>https://wenqi-cui.github.io/project/trajgen-linear/</guid>
      <description>&lt;p&gt;A key barrier to using reinforcement learning (RL) in many real-world applications is the requirement of a large number of system interactions to learn a good control policy. Off-policy and Offline RL methods have been proposed to reduce the number of interactions with the physical environment by learning control policies from historical data. 
However, their performances suffer from the lack of exploration and the distributional shifts in trajectories once controllers are updated. Moreover, most RL methods require that all states are directly observed, which is difficult to be attained in many settings.&lt;/p&gt;
&lt;p&gt;To overcome these challenges, we propose a trajectory generation algorithm, which adaptively generates new trajectories as if the system is being operated and explored under the updated control policies. Motivated by the fundamental lemma for linear systems, assuming sufficient excitation, we generate trajectories from linear combinations of historical trajectories. For linear feedback control, we prove that the algorithm generates trajectories with the exact distribution as if they are sampled from the real system using the updated control policy. In particular, the algorithm extends to systems where the states are not directly observed. Experiments show that the proposed method significantly reduces the number of sampled data needed for RL algorithms.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Structured Neural-PI Control for Networked Systems: Stability and Steady-State Optimality Guarantees</title>
      <link>https://wenqi-cui.github.io/project/neural-pi/</link>
      <pubDate>Wed, 01 Jun 2022 08:00:48 +0000</pubDate>
      <guid>https://wenqi-cui.github.io/project/neural-pi/</guid>
      <description>&lt;p&gt;We study the control of networked systems with the goal of optimizing both transient and steady-state performances while providing stability guarantees. Linear Proportional-Integral (PI) controllers are almost always used in practice, but the linear parameterization of the controller fundamentally limits its performance. Learning-based approaches are becoming popular in designing nonlinear controllers, but the lack of stability guarantees makes the learned controllers difficult to apply in practical applications.&lt;/p&gt;
&lt;p&gt;This paper bridges the gap between neural network-based controller design and the need for stability guarantees. Using equilibrium-independent passivity, a property present in a wide range of physical systems, we propose structured neural-PI controllers that have provable guarantees on stability and zero steady-state output tracking error. If communication between neighbours is available, we further extend the controller to distributedly achieve optimal resource allocation at the steady state. We explicitly characterize the stability conditions and engineer neural networks that satisfy them by design. Experiments on traffic and power networks demonstrate that the proposed approach can improve both transient and steady-state performances compared to existing state-of-the-art, while unstructured neural networks lead to unstable behaviors.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reinforcement Learning for Optimal Frequency Control - A Lyapunov Approach</title>
      <link>https://wenqi-cui.github.io/project/example/</link>
      <pubDate>Fri, 20 May 2022 00:00:00 +0000</pubDate>
      <guid>https://wenqi-cui.github.io/project/example/</guid>
      <description>&lt;p&gt;The increase in penetration of inverter-based resources provides us with more flexibility in frequency regulation compared to conventional linear droop controllers. Using their power electronic interfaces, inverter-based resources can realize almost arbitrary responses to frequency changes. Reinforcement learning (RL) has emerged as a popular method to design these nonlinear controllers to optimize a host of objective functions.&lt;/p&gt;
&lt;p&gt;The key challenge with RL-based approaches is how to enforce the constraint that the learned controller should be stabilizing. In addition, training these controllers is nontrivial because of the time-coupled dynamics of power systems. In this paper, we propose to explicitly engineer the structure of neural network-based controllers such that they guarantee system stability by design. This is done by constraining the network structures using a well-known Lyapunov function. A recurrent RL architecture is used to efficiently train the controllers. The resulting controllers only use local information and outperform linear droop as well as controllers trained using existing state-of-the-art learning approaches.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Equilibrium-Independent Stability Analysis for Distribution Systems with Lossy Transmission Lines</title>
      <link>https://wenqi-cui.github.io/project/lossy-lcss/</link>
      <pubDate>Fri, 06 May 2022 08:00:48 +0000</pubDate>
      <guid>https://wenqi-cui.github.io/project/lossy-lcss/</guid>
      <description>&lt;p&gt;Power distribution systems are becoming much more active with increased penetration of distributed energy resources. Because of the intermittent nature of these resources, the stability of distribution systems under large disturbances and time-varying conditions is becoming a key issue in practical operations. Because the transmission lines in distribution systems are lossy, standard approaches in power system stability analysis do not readily apply and the understanding of transient stability remains open even for simplified models.&lt;/p&gt;
&lt;p&gt;This paper proposes a novel equilibrium-independent transient stability analysis of distribution systems with lossy lines. We certify network-level stability by breaking the network into subsystems, and by looking at the equilibrium-independent passivity of each subsystem, the network stability is certified through a diagonal stability property of the interconnection matrix. This allows the analysis scale to large networked systems with time-varying equilibria. The proposed method gracefully extrapolates between lossless and lossy systems, and provides a simple yet effective approach to optimize control efforts with guaranteed stability regions. Case studies verify that the proposed method is much less conservative than existing approaches and also scales to large systems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Power System Dynamics and Transients: A Frequency Domain Approach</title>
      <link>https://wenqi-cui.github.io/project/fourier-transient/</link>
      <pubDate>Mon, 01 Nov 2021 08:00:48 +0000</pubDate>
      <guid>https://wenqi-cui.github.io/project/fourier-transient/</guid>
      <description>&lt;p&gt;The dynamics of power grids are governed by a large number of nonlinear ordinary differential equations (ODEs). To safely operate the system, operators need to check that the states described by this set of ODEs stay within prescribed limits after various faults. Limited by the size and stiffness of the ODEs, current numerical integration techniques are often too slow to be useful in real-time or large-scale resource allocation problems. In addition, detailed system parameters are often not exactly known. Machine learning approaches have been proposed to reduce the computational efforts, but existing methods generally suffer from overfitting and failures to predict unstable behaviors.&lt;/p&gt;
&lt;p&gt;This paper proposes a novel framework for power system dynamic predictions by learning in the frequency domain. The intuition is that although the system behavior is complex in the time domain, there are relatively few dominate modes in the frequency domain. Therefore, we learn to predict by constructing neural networks with Fourier transform and filtering layers. System topology and fault information are encoded by taking a multi-dimensional Fourier transform, allowing us to leverage the fact that the trajectories are sparse both in time and spatial (across different buses) frequencies. We show that the proposed approach does not need detailed system parameters, speeds up prediction computations by orders of magnitude and is highly accurate for different fault types.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Decentralized Safe Reinforcement Learning for Voltage Control</title>
      <link>https://wenqi-cui.github.io/project/safe-rl-voltage-pscc/</link>
      <pubDate>Sun, 03 Oct 2021 08:00:48 +0000</pubDate>
      <guid>https://wenqi-cui.github.io/project/safe-rl-voltage-pscc/</guid>
      <description>&lt;p&gt;Inverter-based distributed energy resources provide the possibility for fast time-scale voltage control by quickly adjusting their reactive power. The power-electronic interfaces allow these resources to realize almost arbitrary control law, but designing these decentralized controllers is nontrivial. Reinforcement learning (RL) approaches are becoming increasingly popular to search for policy parameterized by neural networks. It is difficult, however, to enforce that the learned controllers are safe, in the sense that they may introduce instabilities into the system.&lt;/p&gt;
&lt;p&gt;This paper proposes a safe learning approach for voltage control. We prove that the system is guaranteed to be exponentially stable if each controller satisfies certain Lipschitz constraints. The set of Lipschitz bound is optimized to enlarge the search space for neural network controllers. We explicitly engineer the structure of neural network controllers such that they satisfy the Lipschitz constraints by design. A decentralized RL framework is constructed to train local neural network controller at each bus in a model-free setting.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lyapunov-Regularized Reinforcement Learning for Power System Transient Stability</title>
      <link>https://wenqi-cui.github.io/project/lyapunov-regularized-reinforcement-learning-for-power-system-transient-stability/</link>
      <pubDate>Thu, 06 May 2021 08:00:48 +0000</pubDate>
      <guid>https://wenqi-cui.github.io/project/lyapunov-regularized-reinforcement-learning-for-power-system-transient-stability/</guid>
      <description>&lt;p&gt;Transient stability of power systems is becoming increasingly important because of the growing integration of renewable resources. These resources lead to a reduction in mechanical inertia but also provide increased flexibility in frequency responses. Namely, their power electronic interfaces can implement almost arbitrary control laws. To design these controllers, reinforcement learning (RL) has emerged as a powerful method in searching for optimal non-linear control policy parameterized by neural networks.&lt;/p&gt;
&lt;p&gt;A key challenge is to enforce that a learned controller must be stabilizing. This paper proposes a Lyapunov regularized RL approach for optimal frequency control for transient stability in lossy networks. Because the lack of an analytical Lyapunov function, we learn a Lyapunov function parameterized by a neural network. The losses are specially designed with respect to the physical power system. The learned neural Lyapunov function is then utilized as a regularization to train the neural network controller by penalizing actions that violate the Lyapunov conditions. Case study shows that introducing the Lyapunov regularization enables the controller to be stabilizing and achieve smaller losses.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
